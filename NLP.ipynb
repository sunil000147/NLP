{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15rsLv-ezm48PZWNn8a65cfkOBrHWg25U",
      "authorship_tag": "ABX9TyNLV6uDuODaNbePsN33Rl3Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunil000147/NLP/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLmymHV7X-zi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import pandas as pd\n",
        "from nltk.tokenize import RegexpTokenizer , sent_tokenize\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "from fake_useragent import UserAgent\n",
        "import requests\n",
        "import urllib.request,sys,time ,requests\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install fake_useragent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xXT_I6HYGbI",
        "outputId": "baf5eb0b-249f-451a-dcd7-aafe9530c89a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fake_useragent\n",
            "  Downloading fake_useragent-1.3.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: fake_useragent\n",
            "Successfully installed fake_useragent-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX0AnM8HYcj6",
        "outputId": "c0d6567d-706b-41f5-fea3-cdb26fb9462c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopWordsFile =     '/content/drive/MyDrive/20211030 Test Assignment/StopWords/StopWords_Generic.txt'\n",
        "positiveWordsFile = '/content/drive/MyDrive/20211030 Test Assignment/MasterDictionary/positive-words.txt'\n",
        "negativeWordsFile = '/content/drive/MyDrive/20211030 Test Assignment/MasterDictionary/negative-words.txt'\n"
      ],
      "metadata": {
        "id": "qOV3zNZJYKRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = pd.read_excel(\"/content/drive/MyDrive/20211030 Test Assignment/Input.xlsx\")\n",
        "input\n",
        "\n",
        "def get_article_names(urls):\n",
        "  titles = []\n",
        "  for i in range (len(urls)):\n",
        "    title = urls[i]\n",
        "    title_clean = title[title.index( \"m/\" ) + 2 :-1]. replace('-' , ' ')\n",
        "    titles.append(title_clean)\n",
        "  return titles\n",
        "\n",
        "urls =input[\"URL\"]\n",
        "urlsTitleDF = get_article_names(urls)\n",
        "urlsTitleDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDXYW_qYbWRm",
        "outputId": "4384a0d7-6cb7-4563-f8e1-107a6cccd4eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rise of telemedicine and its impact on livelihood by 2040 3 2',\n",
              " 'rise of e health and its impact on humans by the year 2030',\n",
              " 'rise of e health and its imapct on humans by the year 2030 2',\n",
              " 'rise of telemedicine and its impact on livelihood by 2040 2',\n",
              " 'rise of telemedicine and its impact on livelihood by 2040 2 2',\n",
              " 'rise of chatbots and its impact on customer support by the year 2040',\n",
              " 'rise of e health and its imapct on humans by the year 2030',\n",
              " 'how does marketing influence businesses and consumers',\n",
              " 'how advertisement increase your market value',\n",
              " 'negative effects of marketing on society',\n",
              " 'how advertisement marketing affects business',\n",
              " 'rising it cities will impact the economy environment infrastructure and city life by the year 2035',\n",
              " 'rise of ott platform and its impact on entertainment industry by the year 2030',\n",
              " 'rise of electric vehicles and its impact on livelihood by 2040',\n",
              " 'rise of electric vehicle and its impact on livelihood by the year 2040',\n",
              " 'oil prices by the year 2040 and how it will impact the world economy',\n",
              " 'an outlook of healthcare by the year 2040 and how it will impact human lives',\n",
              " 'ai in healthcare to improve patient outcomes',\n",
              " 'what if the creation is taking over the creator',\n",
              " 'what jobs will robots take from humans in the future',\n",
              " 'will machine replace the human in the future of work',\n",
              " 'will ai replace us or work with us',\n",
              " 'man and machines together machines are more diligent than humans blackcoffe',\n",
              " 'in future or in upcoming years humans and machines are going to work together in every field of work',\n",
              " 'how neural networks can be applied in various areas in the future',\n",
              " 'how machine learning will affect your business',\n",
              " 'deep learning impact on areas of e learning',\n",
              " 'how to protect future data and its privacy blackcoffer',\n",
              " 'how machines ai automations and robo human are effective in finance and banking',\n",
              " 'ai human robotics machine future planet blackcoffer thinking jobs workplace',\n",
              " 'how ai will change the world blackcoffer',\n",
              " 'future of work how ai has entered the workplace',\n",
              " 'ai tool alexa google assistant finance banking tool future',\n",
              " 'ai healthcare revolution ml technology algorithm google analytics industrialrevolution',\n",
              " 'all you need to know about online marketing',\n",
              " 'evolution of advertising industry',\n",
              " 'how data analytics can help your business respond to the impact of covid 19',\n",
              " 'covid 19 environmental impact for the future',\n",
              " 'environmental impact of the covid 19 pandemic lesson for the future',\n",
              " 'how data analytics and ai are used to halt the covid 19 pandemic',\n",
              " 'difference between artificial intelligence machine learning statistics and data mining',\n",
              " 'how python became the first choice for data science',\n",
              " 'how google fit measure heart and respiratory rates using a phone',\n",
              " 'what is the future of mobile apps',\n",
              " 'impact of ai in health and medicine',\n",
              " 'telemedicine what patients like and dislike about it',\n",
              " 'how we forecast future technologies',\n",
              " 'can robots tackle late life loneliness',\n",
              " 'embedding care robots into society socio technical considerations',\n",
              " 'management challenges for future digitalization of healthcare services',\n",
              " 'are we any closer to preventing a nuclear holocaust',\n",
              " 'will technology eliminate the need for animal testing in drug development',\n",
              " 'will we ever understand the nature of consciousness',\n",
              " 'will we ever colonize outer space',\n",
              " 'what is the chance homo sapiens will survive for the next 500 years',\n",
              " 'why does your business need a chatbot',\n",
              " 'how you lead a project or a team without any technical expertise',\n",
              " 'can you be great leader without technical expertise',\n",
              " 'how does artificial intelligence affect the environment',\n",
              " 'how to overcome your fear of making mistakes 2',\n",
              " 'is perfection the greatest enemy of productivity',\n",
              " 'global financial crisis 2008 causes effects and its solution',\n",
              " 'gender diversity and equality in the tech industry',\n",
              " 'how to overcome your fear of making mistakes',\n",
              " 'how small business can survive the coronavirus crisis',\n",
              " 'impacts of covid 19 on vegetable vendors and food stalls',\n",
              " 'impacts of covid 19 on vegetable vendors',\n",
              " 'impact of covid 19 pandemic on tourism aviation industries',\n",
              " 'impact of covid 19 pandemic on sports events around the world',\n",
              " 'changing landscape and emerging trends in the indian it ites industry',\n",
              " 'online gaming adolescent online gaming effects demotivated depression musculoskeletal and psychosomatic symptoms',\n",
              " 'human rights outlook',\n",
              " 'how voice search makes your business a successful business',\n",
              " 'how the covid 19 crisis is redefining jobs and services',\n",
              " 'how to increase social media engagement for marketers',\n",
              " 'impacts of covid 19 on streets sides food stalls',\n",
              " 'coronavirus impact on energy markets 2',\n",
              " 'coronavirus impact on the hospitality industry 5',\n",
              " 'lessons from the past some key learnings relevant to the coronavirus crisis 4',\n",
              " 'estimating the impact of covid 19 on the world of work 2',\n",
              " 'estimating the impact of covid 19 on the world of work 3',\n",
              " 'travel and tourism outlook',\n",
              " 'gaming disorder and effects of gaming on health',\n",
              " 'what is the repercussion of the environment due to the covid 19 pandemic situation',\n",
              " 'what is the repercussion of the environment due to the covid 19 pandemic situation 2',\n",
              " 'impact of covid 19 pandemic on office space and co working industries',\n",
              " 'contribution of handicrafts visual arts literature in the indian economy',\n",
              " 'how covid 19 is impacting payment preferences',\n",
              " 'how will covid 19 affect the world of work 2',\n",
              " 'lessons from the past some key learnings relevant to the coronavirus crisis',\n",
              " 'covid 19 how have countries been responding',\n",
              " 'coronavirus impact on the hospitality industry 2',\n",
              " 'how will covid 19 affect the world of work 3',\n",
              " 'coronavirus impact on the hospitality industry 3',\n",
              " 'estimating the impact of covid 19 on the world of work',\n",
              " 'covid 19 how have countries been responding 2',\n",
              " 'how will covid 19 affect the world of work 4',\n",
              " 'lessons from the past some key learnings relevant to the coronavirus crisis 2',\n",
              " 'lessons from the past some key learnings relevant to the coronavirus crisis 3',\n",
              " 'coronavirus impact on the hospitality industry 4',\n",
              " 'why scams like nirav modi happen with indian banks',\n",
              " 'impact of covid 19 on the global economy',\n",
              " 'impact of covid 19coronavirus on the indian economy 2',\n",
              " 'impact of covid 19 on the global economy 2',\n",
              " 'impact of covid 19 coronavirus on the indian economy 3',\n",
              " 'should celebrities be allowed to join politics',\n",
              " 'how prepared is india to tackle a possible covid 19 outbreak',\n",
              " 'how will covid 19 affect the world of work',\n",
              " 'controversy as a marketing strategy',\n",
              " 'coronavirus impact on the hospitality industry',\n",
              " 'coronavirus impact on energy markets',\n",
              " 'what are the key policies that will mitigate the impacts of covid 19 on the world of work',\n",
              " 'marketing drives results with a focus on problems',\n",
              " 'continued demand for sustainability']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://insights.blackcoffer.com/rise-of-chatbots-and-its-impact-on-customer-support-by-the-year-2040/\"\n",
        "\n",
        "page=requests.get(url , headers={\"User-Agent\": \"XY\"})\n",
        "soup = BeautifulSoup(page.text , 'html.parser')\n",
        "#get title\n",
        "title = soup . find(\"h1\",attrs = { 'class' : 'entry-title'}).get_text()\n",
        "\n",
        "#get article text\n",
        "text = soup . find(attrs = { 'class' : 'td-post-content'}).get_text()\n",
        "# break into lines and remove leading and trailing space on each\n",
        "lines = (line.strip() for line in text.splitlines())\n",
        "# break multi-headlines into a line each\n",
        "chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
        "# drop blank lines\n",
        "text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
        "\n"
      ],
      "metadata": {
        "id": "rTK0FTe3bmYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading positive words\n",
        "with open(positiveWordsFile,'r') as posfile:\n",
        "    positivewords=posfile.read().lower()\n",
        "positiveWordList=positivewords.split('\\n')\n",
        "\n",
        "\n",
        "# Loading negative words\n",
        "with open(nagitiveWordsFile ,'r' ,  encoding=\"ISO-8859-1\") as negfile:\n",
        "    negativeword=negfile.read().lower()\n",
        "negativeWordList=negativeword.split('\\n')\n",
        "\n",
        "#Loading stop words dictionary for removing stop words\n",
        "\n",
        "with open(stopWordsFile ,'r') as stop_words:\n",
        "    stopWords = stop_words.read().lower()\n",
        "stopWordList = stopWords.split('\\n')\n",
        "stopWordList[-1:] = []\n",
        "\n",
        "\n",
        "\n",
        "display( positiveWordList[:6]  , negativeWordList[:6] , stopWordList[:6])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "vhOv-qzYcI7j",
        "outputId": "d90674f4-c5d6-4291-a635-e087590a3cca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['a+', 'abound', 'abounds', 'abundance', 'abundant', 'accessable']"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable', 'abominably']"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['about', 'above', 'after', 'again', 'all', 'am']"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizeing module and filtering tokens using stop words list, removing punctuations\n",
        "def tokenizer(text):\n",
        "    text = text.lower()\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    filtered_words = list(filter(lambda token: token not in stopWordList, tokens))\n",
        "    return filtered_words\n",
        "\n",
        "def positive_score (text):\n",
        "  posword=0\n",
        "  tokenphrase = tokenizer(text)\n",
        "  for word in tokenphrase :\n",
        "    if word in positiveWordList:\n",
        "       posword+=1\n",
        "\n",
        "    retpos = posword\n",
        "    return retpos\n",
        "\n",
        "def negative_score (text):\n",
        "  negword=0\n",
        "  tokenphrase = tokenizer(text)\n",
        "  for word in tokenphrase :\n",
        "    if word in negativeWordList : negword +=1\n",
        "\n",
        "    retneg = negword\n",
        "    return retneg\n",
        "\n",
        "def polarity_score (positive_score , negative_score) :\n",
        "  return (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)\n",
        "#################################################\n",
        "def total_word_count(text):\n",
        "    tokens = tokenizer(text)\n",
        "    return len(tokens)\n",
        "#############################################\n",
        "def AverageSentenceLenght (text):\n",
        "  Wordcount = len(tokenizer (text))\n",
        "  SentenceCount = len (sent_tokenize(text))\n",
        "  if SentenceCount > 0 : Average_Sentence_Lenght = Wordcount / SentenceCount\n",
        "\n",
        "  avg = Average_Sentence_Lenght\n",
        "\n",
        "  return round(avg)\n",
        "\n",
        "\n",
        "# Counting complex words\n",
        "def complex_word_count(text):\n",
        "    tokens = tokenizer(text)\n",
        "    complexWord = 0\n",
        "\n",
        "    for word in tokens:\n",
        "        vowels=0\n",
        "        if word.endswith(('es','ed')):\n",
        "            pass\n",
        "        else:\n",
        "            for w in word:\n",
        "                if(w=='a' or w=='e' or w=='i' or w=='o' or w=='u'):\n",
        "                    vowels += 1\n",
        "            if(vowels > 2):\n",
        "                complexWord += 1\n",
        "    return complexWord\n",
        "\n",
        "def percentage_complex_word(text):\n",
        "    tokens = tokenizer(text)\n",
        "    complexWord = 0\n",
        "    complex_word_percentage = 0\n",
        "\n",
        "    for word in tokens:\n",
        "        vowels=0\n",
        "        if word.endswith(('es','ed')):\n",
        "            pass\n",
        "        else:\n",
        "            for w in word:\n",
        "                if(w=='a' or w=='e' or w=='i' or w=='o' or w=='u'):\n",
        "                    vowels += 1\n",
        "            if(vowels > 2):\n",
        "                complexWord += 1\n",
        "    if len(tokens) != 0:\n",
        "        complex_word_percentage = complexWord/len(tokens)\n",
        "\n",
        "    return complex_word_percentage\n",
        "\n",
        "def fog_index(averageSentenceLength, percentageComplexWord):\n",
        "    fogIndex = 0.4 * (averageSentenceLength + percentageComplexWord)\n",
        "    return fogIndex\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZW-4DDAmcP8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "URLS = input['URL']\n",
        "\n",
        "URLS\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWvxjP70cYBk",
        "outputId": "18aa78e1-909a-4205-d022-85b4bf362878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      https://insights.blackcoffer.com/rise-of-telem...\n",
              "1      https://insights.blackcoffer.com/rise-of-e-hea...\n",
              "2      https://insights.blackcoffer.com/rise-of-e-hea...\n",
              "3      https://insights.blackcoffer.com/rise-of-telem...\n",
              "4      https://insights.blackcoffer.com/rise-of-telem...\n",
              "                             ...                        \n",
              "109    https://insights.blackcoffer.com/coronavirus-i...\n",
              "110    https://insights.blackcoffer.com/coronavirus-i...\n",
              "111    https://insights.blackcoffer.com/what-are-the-...\n",
              "112    https://insights.blackcoffer.com/marketing-dri...\n",
              "113    https://insights.blackcoffer.com/continued-dem...\n",
              "Name: URL, Length: 114, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corps =[]\n",
        "for url in URLS:\n",
        "\n",
        "  page=requests.get(url , headers={\"User-Agent\": \"XY\"})\n",
        "  soup = BeautifulSoup(page.text , 'html.parser')\n",
        "  #get title\n",
        "  title = soup . find(\"h1\",attrs = { 'class' : 'entry-title'}).get_text()\n",
        "\n",
        "  #get article text\n",
        "  text = soup . find(attrs = { 'class' : 'td-post-content'}).get_text()\n",
        "  # break into lines and remove leading and trailing space on each\n",
        "  lines = (line.strip() for line in text.splitlines())\n",
        "  # break multi-headlines into a line each\n",
        "  chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
        "  # drop blank lines\n",
        "  text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
        "  corps.append(text)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jvEO0QvYciSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corps = []\n",
        "for url in URLS:\n",
        "    page = requests.get(url, headers={\"User-Agent\": \"XY\"})\n",
        "    soup = BeautifulSoup(page.text, 'html.parser')\n",
        "\n",
        "    # Get title\n",
        "    title_element = soup.find(\"h1\", attrs={'class': 'entry-title'})\n",
        "    if title_element:\n",
        "        title = title_element.get_text()\n",
        "    else:\n",
        "        title = \"Title not found\"  # You can set a default value or handle it as needed\n",
        "\n",
        "    # Get article text\n",
        "    text_element = soup.find(attrs={'class': 'td-post-content'})\n",
        "    if text_element:\n",
        "        text = text_element.get_text()\n",
        "    else:\n",
        "        text = \"Article text not found\"  # You can set a default value or handle it as needed\n",
        "\n",
        "    # Process and append the text\n",
        "    lines = (line.strip() for line in text.splitlines())\n",
        "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
        "    text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
        "    corps.append({'title': title, 'text': text})\n"
      ],
      "metadata": {
        "id": "td2HJRstcwHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = pd.DataFrame(corps,urlsTitleDF)\n",
        "df = pd.DataFrame({'title':urlsTitleDF,'corps': corps})\n",
        "df[\"total word count\"] = df[\"corps\"] . apply (total_word_count)\n",
        "df[\"percentage_complex_word\"] = df[\"corps\"] . apply (percentage_complex_word)\n",
        "df[\"complex_word_count\"] = df[\"corps\"] . apply (complex_word_count)\n",
        "df[\"AverageSentenceLenght\"] = df[\"corps\"] . apply (AverageSentenceLenght)\n",
        "df[\"positive_score\"] = df[\"corps\"] . apply (positive_score)\n",
        "df[\"negative_score\"] = df[\"corps\"] . apply (negative_score)\n",
        "df[\"polarity_score\"] = np.vectorize(polarity_score)(df['positive_score'],df['negative_score'])\n",
        "\n",
        "df\n"
      ],
      "metadata": {
        "id": "OHj2k7p6cmot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_score(positiveWordsFile)\n",
        "negative_score(negativeWordsFile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHKoNj5Ai0XD",
        "outputId": "5270a7d0-865c-4e09-b46c-7aac81d22561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define your text processing functions\n",
        "def total_word_count(text):\n",
        "    tokens = tokenizer(text)\n",
        "    return len(tokens)\n",
        "\n",
        "# Define your other text processing functions (e.g., percentage_complex_word, complex_word_count, etc.)\n",
        "\n",
        "# Create a DataFrame with your data\n",
        "df = pd.DataFrame({'title': urlsTitleDF, 'corps': corps})\n",
        "\n",
        "# Apply your text processing functions to create new columns\n",
        "df[\"total word count\"] = df[\"corps\"].apply(lambda text: total_word_count(text.get('corps', '')))\n",
        "# Apply your other text processing functions similarly\n",
        "\n",
        "df[\"positive_score\"] = df[\"corps\"] . apply (positive_score)\n",
        "df[\"negative_score\"] = df[\"corps\"] . apply (negative_score)\n",
        "# Calculate polarity_score\n",
        "df[\"polarity_score\"] = df[\"positive_score\"] - df[\"negative_score\"]\n",
        "\n",
        "# Display the DataFrame\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "8iRs4I_EdWVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final.to_excel('Output Data Structure.xlsx', encoding='utf-8')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buu3cKt1hKTJ",
        "outputId": "be55bc4a-fbe5-41e0-c02a-ff167e6669fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py:211: FutureWarning: the 'encoding' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'encoding'\n",
            "  return func(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mph0ysK7hTN0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}